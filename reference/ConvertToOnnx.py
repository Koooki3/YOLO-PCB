import torch.onnx
from ultralytics import YOLO
from copy import deepcopy
import torch
import os

def load_yolo_model(modelpath, device='cuda'):
    """
    åŠ è½½ YOLO æ¨¡å‹å¹¶è¿›è¡Œé¢„å¤„ç†
    
    Args:
        modelpath: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        device: è®¡ç®—è®¾å¤‡ ('cuda' æˆ– 'cpu')
    
    Returns:
        å¤„ç†åçš„æ¨¡å‹
    """
    yolo = YOLO(modelpath)
    model = yolo.model
    
    model = deepcopy(model).to(device)
    for p in model.parameters():
        p.requires_grad = False
    model.fuse().eval()  # å·ç§¯å’Œ BN èåˆ
    model.to(device)
    return model

def convert_yolo_to_onnx(model_path, output_path, input_size=(640, 640), device='cuda'):
    """
    å°† YOLO æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼
    
    Args:
        model_path: è¾“å…¥çš„ .pt æ¨¡å‹è·¯å¾„
        output_path: è¾“å‡ºçš„ .onnx æ¨¡å‹è·¯å¾„
        input_size: è¾“å…¥å›¾åƒå¤§å° (height, width)
        device: è®¡ç®—è®¾å¤‡
    
    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    
    # 1. åŠ è½½ PyTorch æ¨¡å‹
    model = load_yolo_model(model_path, device)
    model.eval()  # åˆ‡æ¢åˆ°æ¨ç†æ¨¡å¼
    
    # 2. åˆ›å»ºè¾“å…¥ç¤ºä¾‹
    # YOLO æ¨¡å‹é€šå¸¸æ¥å— [batch_size, 3, height, width] çš„è¾“å…¥
    dummy_input = torch.randn(1, 3, input_size[0], input_size[1]).to(device)
    
    # 3. ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # 4. å°†æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼
    print(f"æ­£åœ¨è½¬æ¢ä¸º ONNX æ ¼å¼ï¼Œè¾“å‡ºè·¯å¾„: {output_path}")
    torch.onnx.export(
        model,                          # æ¨¡å‹
        dummy_input,                    # æ¨¡å‹è¾“å…¥
        output_path,                    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
        export_params=True,             # æ˜¯å¦å¯¼å‡ºè®­ç»ƒçš„å‚æ•°
        opset_version=12,               # ONNX çš„ opset ç‰ˆæœ¬ (æ¨èä½¿ç”¨ 11 æˆ–æ›´é«˜)
        do_constant_folding=True,       # æ˜¯å¦æ‰§è¡Œå¸¸é‡æŠ˜å 
        input_names=['images'],         # è¾“å…¥èŠ‚ç‚¹åç§°
        output_names=['outputs'],       # è¾“å‡ºèŠ‚ç‚¹åç§°
        dynamic_axes=None,
        verbose=False                   # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    )
    
    print(f"âœ… æ¨¡å‹å·²æˆåŠŸè½¬æ¢ä¸º ONNX æ ¼å¼!")
    print(f"ğŸ“ ä¿å­˜è·¯å¾„: {output_path}")
    print(f"ğŸ“ è¾“å…¥å¤§å°: {input_size}")
    print(f"ğŸ’» è®¾å¤‡: {device}")
    
    return output_path

def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    # é…ç½®å‚æ•°
    model_path = r'D:\Python-Git\runs\detect\yolo11n-arcuchi-swanlab\weights\best.pt'
    output_path = r'D:\Python-Git\runs\detect\yolo11n-arcuchi-swanlab\weights\best.onnx'
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {model_path}")
        return
    
    try:
        # è½¬æ¢ä¸º ONNX
        convert_yolo_to_onnx(
            model_path=model_path,
            output_path=output_path,
            input_size=(640, 640),  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´è¾“å…¥å¤§å°
            device='cuda' if torch.cuda.is_available() else 'cpu'
        )
        
        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
            print(f"âœ… ONNX æ¨¡å‹æ–‡ä»¶éªŒè¯æˆåŠŸ!")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        else:
            print("âŒ è½¬æ¢å¤±è´¥: è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ")
            
    except Exception as e:
        print(f"âŒ è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        print("è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦æŸåæˆ–è·¯å¾„æ˜¯å¦æ­£ç¡®")

if __name__ == "__main__":
    main()