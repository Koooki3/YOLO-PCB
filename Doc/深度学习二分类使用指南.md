# VisualRobot 深度学习二分类使用指南

## 概述

本指南详细介绍了如何在 VisualRobot 项目中使用深度学习二分类功能。该功能基于 OpenCV DNN 模块实现，支持多种深度学习框架的模型格式，适用于工业视觉检测中的缺陷分类、质量控制等应用场景。

## 目录

1. [功能特性](#功能特性)
2. [系统要求](#系统要求)
3. [快速开始](#快速开始)
4. [详细使用说明](#详细使用说明)
5. [模型准备](#模型准备)
6. [API 参考](#api-参考)
7. [示例代码](#示例代码)
8. [性能优化](#性能优化)
9. [故障排除](#故障排除)
10. [常见问题](#常见问题)

## 功能特性

### 核心功能
- **多格式模型支持**: ONNX、TensorFlow、Caffe、Darknet
- **二分类任务**: 专门针对二分类场景优化
- **批量处理**: 支持单张和批量图像分类
- **实时处理**: 集成到相机采集流程中
- **置信度控制**: 可配置的置信度阈值
- **结果结构化**: 提供详细的分类结果信息

### 技术特点
- **高性能**: 基于 OpenCV DNN 优化
- **易集成**: Qt 信号槽机制，无缝集成到现有系统
- **灵活配置**: 支持多种预处理参数
- **错误处理**: 完善的异常处理和错误报告
- **内存优化**: 智能内存管理，避免内存泄漏

## 系统要求

### 硬件要求
- **CPU**: Intel i5 或同等性能处理器
- **内存**: 最少 4GB RAM（推荐 8GB 以上）
- **存储**: 至少 1GB 可用空间用于模型文件
- **GPU**: 可选，支持 CUDA 加速（需要 NVIDIA GPU）

### 软件要求
- **操作系统**: Windows 10/11, Linux Ubuntu 18.04+
- **Qt**: 5.12 或更高版本
- **OpenCV**: 4.5 或更高版本（需要 DNN 模块）
- **编译器**: MSVC 2019+ 或 GCC 7+

### 依赖库
```cpp
// 必需的头文件
#include <opencv2/opencv.hpp>
#include <opencv2/dnn.hpp>
#include <QtCore>
#include <QtWidgets>
```

## 快速开始

### 1. 准备模型文件

将训练好的二分类模型放置在 `Data/Models/` 目录下：

```
Data/
├── Models/
│   ├── binary_classifier.onnx      # ONNX 模型
│   ├── binary_classifier.pb        # TensorFlow 模型
│   └── README_MODELS.md            # 模型说明文档
└── Labels/
    └── class_labels.txt            # 类别标签文件
```

### 2. 配置类别标签

编辑 `Data/Labels/class_labels.txt` 文件：

```
Good
Defect
```

### 3. 基本使用代码

```cpp
#include "DLProcessor.h"

// 创建处理器实例
DLProcessor* processor = new DLProcessor();

// 初始化模型
bool success = processor->initModel("Data/Models/binary_classifier.onnx");
if (!success) {
    qDebug() << "模型加载失败";
    return;
}

// 加载类别标签
processor->loadClassLabels("Data/Labels/class_labels.txt");

// 设置参数
processor->setModelParams(0.5f, 0.4f);  // 置信度阈值, NMS阈值
processor->setInputSize(cv::Size(224, 224));  // 输入尺寸

// 加载图像并分类
cv::Mat image = cv::imread("test_image.jpg");
ClassificationResult result;

if (processor->classifyImage(image, result)) {
    qDebug() << "分类结果:" << result.className.c_str()
             << "置信度:" << result.confidence;
} else {
    qDebug() << "分类失败";
}
```

### 4. 运行演示程序

```cpp
#include "DLExample.h"
#include <QApplication>

int main(int argc, char *argv[])
{
    QApplication app(argc, argv);
    
    DLExample window;
    window.show();
    
    return app.exec();
}
```

## 详细使用说明

### DLProcessor 类详解

#### 初始化和配置

```cpp
// 1. 创建实例
DLProcessor* processor = new DLProcessor(parent);

// 2. 初始化模型
// 对于 ONNX/TensorFlow 模型
bool success = processor->initModel("model.onnx");

// 对于 Caffe 模型（需要 prototxt 文件）
bool success = processor->initModel("model.caffemodel", "model.prototxt");

// 对于 Darknet 模型（需要 cfg 文件）
bool success = processor->initModel("model.weights", "model.cfg");

// 3. 加载类别标签
processor->loadClassLabels("class_labels.txt");

// 4. 设置模型参数
processor->setModelParams(
    0.5f,    // 置信度阈值
    0.4f     // NMS 阈值（对于某些模型）
);

// 5. 设置输入尺寸
processor->setInputSize(cv::Size(224, 224));

// 6. 设置预处理参数
processor->setPreprocessParams(
    cv::Scalar(0.485, 0.456, 0.406),  // 均值
    cv::Scalar(0.229, 0.224, 0.225),  // 标准差
    1.0/255.0,                        // 缩放因子
    false                             // 是否交换 R 和 B 通道
);
```

#### 单张图像分类

```cpp
cv::Mat image = cv::imread("image.jpg");
ClassificationResult result;

if (processor->classifyImage(image, result)) {
    if (result.isValid) {
        std::cout << "类别: " << result.className << std::endl;
        std::cout << "ID: " << result.classId << std::endl;
        std::cout << "置信度: " << result.confidence << std::endl;
    } else {
        std::cout << "置信度过低，结果无效" << std::endl;
    }
} else {
    std::cout << "分类失败" << std::endl;
}
```

#### 批量图像分类

```cpp
// 准备图像列表
std::vector<cv::Mat> images;
images.push_back(cv::imread("image1.jpg"));
images.push_back(cv::imread("image2.jpg"));
images.push_back(cv::imread("image3.jpg"));

// 执行批量分类
std::vector<ClassificationResult> results;
if (processor->classifyBatch(images, results)) {
    for (size_t i = 0; i < results.size(); ++i) {
        const auto& result = results[i];
        std::cout << "图像 " << i << ": " 
                  << result.className << " (" 
                  << result.confidence << ")" << std::endl;
    }
}
```

#### 信号槽机制

```cpp
// 连接信号
connect(processor, &DLProcessor::classificationComplete,
        this, &MyClass::onClassificationComplete);

connect(processor, &DLProcessor::batchProcessingComplete,
        this, &MyClass::onBatchProcessingComplete);

connect(processor, &DLProcessor::errorOccurred,
        this, &MyClass::onDLError);

// 槽函数实现
void MyClass::onClassificationComplete(const ClassificationResult& result) {
    // 处理单张图像分类结果
}

void MyClass::onBatchProcessingComplete(const std::vector<ClassificationResult>& results) {
    // 处理批量分类结果
}

void MyClass::onDLError(const QString& error) {
    // 处理错误
}
```

### 集成到现有系统

#### 与相机系统集成

```cpp
// 在相机回调中使用
void CameraCallback::onFrameReceived(const cv::Mat& frame) {
    // 执行深度学习分类
    ClassificationResult result;
    if (dlProcessor->classifyImage(frame, result)) {
        // 根据分类结果执行相应操作
        if (result.className == "Defect" && result.isValid) {
            // 检测到缺陷，触发报警
            emit defectDetected(result);
        }
    }
}
```

#### 与主窗口集成

```cpp
// 在 MainWindow 中添加深度学习功能
class MainWindow : public QMainWindow {
private:
    DLProcessor* dlProcessor_;
    
public slots:
    void onDLClassificationComplete(const ClassificationResult& result);
    
private slots:
    void enableDLProcessing();
    void configureDLParameters();
};

void MainWindow::enableDLProcessing() {
    // 初始化深度学习处理器
    dlProcessor_ = new DLProcessor(this);
    
    // 连接信号
    connect(dlProcessor_, &DLProcessor::classificationComplete,
            this, &MainWindow::onDLClassificationComplete);
    
    // 加载模型
    if (dlProcessor_->initModel("Data/Models/default_model.onnx")) {
        dlProcessor_->loadClassLabels("Data/Labels/class_labels.txt");
        statusBar()->showMessage("深度学习模型已加载");
    }
}
```

## 模型准备

### 支持的模型格式

#### 1. ONNX 模型 (推荐)
```bash
# 模型文件
model.onnx

# 使用方式
processor->initModel("model.onnx");
```

#### 2. TensorFlow 模型
```bash
# 模型文件
model.pb

# 使用方式
processor->initModel("model.pb");
```

#### 3. Caffe 模型
```bash
# 需要两个文件
model.caffemodel  # 权重文件
model.prototxt    # 网络结构文件

# 使用方式
processor->initModel("model.caffemodel", "model.prototxt");
```

#### 4. Darknet 模型
```bash
# 需要两个文件
model.weights     # 权重文件
model.cfg         # 配置文件

# 使用方式
processor->initModel("model.weights", "model.cfg");
```

### 模型要求

#### 输入要求
- **输入格式**: 单通道或三通道图像
- **数据类型**: float32
- **数值范围**: 通常为 [0,1] 或 [-1,1]
- **尺寸**: 固定尺寸（如 224x224, 256x256）

#### 输出要求
- **二分类输出**: 2个类别的概率或logits
- **输出格式**: 
  - Sigmoid: 单个值 [0,1]
  - Softmax: 两个值，和为1
- **数据类型**: float32

### 模型转换示例

#### PyTorch 到 ONNX
```python
import torch
import torch.onnx

# 假设有一个训练好的模型
model = YourBinaryClassifier()
model.load_state_dict(torch.load('model.pth'))
model.eval()

# 创建示例输入
dummy_input = torch.randn(1, 3, 224, 224)

# 导出为 ONNX
torch.onnx.export(
    model,
    dummy_input,
    "binary_classifier.onnx",
    export_params=True,
    opset_version=11,
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={
        'input': {0: 'batch_size'},
        'output': {0: 'batch_size'}
    }
)
```

#### TensorFlow 到 ONNX
```python
import tensorflow as tf
import tf2onnx

# 加载 TensorFlow 模型
model = tf.keras.models.load_model('model.h5')

# 转换为 ONNX
spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32, name="input"),)
output_path = "binary_classifier.onnx"

model_proto, _ = tf2onnx.convert.from_keras(
    model, 
    input_signature=spec, 
    opset=11, 
    output_path=output_path
)
```

## API 参考

### DLProcessor 类

#### 构造函数
```cpp
DLProcessor(QObject* parent = nullptr)
```

#### 公共方法

##### initModel
```cpp
bool initModel(const std::string& modelPath, const std::string& configPath = "")
```
- **功能**: 初始化深度学习模型
- **参数**: 
  - `modelPath`: 模型文件路径
  - `configPath`: 配置文件路径（可选）
- **返回值**: 成功返回 true，失败返回 false

##### classifyImage
```cpp
bool classifyImage(const cv::Mat& frame, ClassificationResult& result)
```
- **功能**: 对单张图像进行分类
- **参数**:
  - `frame`: 输入图像
  - `result`: 输出分类结果
- **返回值**: 成功返回 true，失败返回 false

##### classifyBatch
```cpp
bool classifyBatch(const std::vector<cv::Mat>& images, std::vector<ClassificationResult>& results)
```
- **功能**: 批量图像分类
- **参数**:
  - `images`: 输入图像列表
  - `results`: 输出分类结果列表
- **返回值**: 成功返回 true，失败返回 false

##### setModelParams
```cpp
void setModelParams(float confidenceThreshold, float nmsThreshold)
```
- **功能**: 设置模型参数
- **参数**:
  - `confidenceThreshold`: 置信度阈值 (0.0-1.0)
  - `nmsThreshold`: NMS阈值 (0.0-1.0)

##### setInputSize
```cpp
void setInputSize(const cv::Size& size)
```
- **功能**: 设置模型输入尺寸
- **参数**: `size`: 输入图像尺寸

##### loadClassLabels
```cpp
bool loadClassLabels(const std::string& labelPath)
```
- **功能**: 加载类别标签文件
- **参数**: `labelPath`: 标签文件路径
- **返回值**: 成功返回 true，失败返回 false

##### setClassLabels
```cpp
void setClassLabels(const std::vector<std::string>& labels)
```
- **功能**: 直接设置类别标签
- **参数**: `labels`: 类别标签列表

##### setPreprocessParams
```cpp
void setPreprocessParams(const cv::Scalar& mean, const cv::Scalar& std, double scaleFactor, bool swapRB)
```
- **功能**: 设置预处理参数
- **参数**:
  - `mean`: 均值
  - `std`: 标准差
  - `scaleFactor`: 缩放因子
  - `swapRB`: 是否交换R和B通道

#### 信号

##### classificationComplete
```cpp
void classificationComplete(const ClassificationResult& result)
```
- **功能**: 单张图像分类完成信号
- **参数**: `result`: 分类结果

##### batchProcessingComplete
```cpp
void batchProcessingComplete(const std::vector<ClassificationResult>& results)
```
- **功能**: 批量分类完成信号
- **参数**: `results`: 批量分类结果

##### errorOccurred
```cpp
void errorOccurred(const QString& error)
```
- **功能**: 错误发生信号
- **参数**: `error`: 错误信息

### ClassificationResult 结构体

```cpp
struct ClassificationResult {
    int classId;            // 类别ID
    float confidence;       // 置信度
    std::string className;  // 类别名称
    bool isValid;          // 结果是否有效
};
```

## 示例代码

### 完整的分类应用示例

```cpp
#include <QApplication>
#include <QMainWindow>
#include <QVBoxLayout>
#include <QHBoxLayout>
#include <QPushButton>
#include <QLabel>
#include <QFileDialog>
#include <QMessageBox>
#include "DLProcessor.h"

class ClassificationApp : public QMainWindow
{
    Q_OBJECT

public:
    ClassificationApp(QWidget *parent = nullptr) : QMainWindow(parent)
    {
        setupUI();
        setupDL();
    }

private slots:
    void loadModel()
    {
        QString fileName = QFileDialog::getOpenFileName(this,
            "选择模型文件", "", "模型文件 (*.onnx *.pb *.caffemodel)");
        
        if (!fileName.isEmpty()) {
            if (dlProcessor_->initModel(fileName.toStdString())) {
                dlProcessor_->loadClassLabels("Data/Labels/class_labels.txt");
                statusLabel_->setText("模型加载成功");
            } else {
                QMessageBox::warning(this, "错误", "模型加载失败");
            }
        }
    }
    
    void classifyImage()
    {
        QString fileName = QFileDialog::getOpenFileName(this,
            "选择图像文件", "", "图像文件 (*.jpg *.png *.bmp)");
        
        if (!fileName.isEmpty()) {
            cv::Mat image = cv::imread(fileName.toStdString());
            ClassificationResult result;
            
            if (dlProcessor_->classifyImage(image, result)) {
                QString resultText = QString("类别: %1\n置信度: %2")
                    .arg(QString::fromStdString(result.className))
                    .arg(result.confidence);
                resultLabel_->setText(resultText);
            }
        }
    }

private:
    void setupUI()
    {
        QWidget* central = new QWidget(this);
        setCentralWidget(central);
        
        QVBoxLayout* layout = new QVBoxLayout(central);
        
        QPushButton* loadBtn = new QPushButton("加载模型");
        connect(loadBtn, &QPushButton::clicked, this, &ClassificationApp::loadModel);
        layout->addWidget(loadBtn);
        
        QPushButton* classifyBtn = new QPushButton("分类图像");
        connect(classifyBtn, &QPushButton::clicked, this, &ClassificationApp::classifyImage);
        layout->addWidget(classifyBtn);
        
        statusLabel_ = new QLabel("就绪");
        layout->addWidget(statusLabel_);
        
        resultLabel_ = new QLabel("等待分类结果...");
        layout->addWidget(resultLabel_);
    }
    
    void setupDL()
    {
        dlProcessor_ = new DLProcessor(this);
        dlProcessor_->setModelParams(0.5f, 0.4f);
        dlProcessor_->setInputSize(cv::Size(224, 224));
    }

private:
    DLProcessor* dlProcessor_;
    QLabel* statusLabel_;
    QLabel* resultLabel_;
};

int main(int argc, char *argv[])
{
    QApplication app(argc, argv);
    
    ClassificationApp window;
    window.show();
    
    return app.exec();
}

#include "main.moc"
```

### 实时相机分类示例

```cpp
#include "DLProcessor.h"
#include <opencv2/opencv.hpp>

class RealTimeClassifier
{
public:
    RealTimeClassifier()
    {
        dlProcessor_ = new DLProcessor();
        dlProcessor_->initModel("Data/Models/binary_classifier.onnx");
        dlProcessor_->loadClassLabels("Data/Labels/class_labels.txt");
        dlProcessor_->setModelParams(0.7f, 0.4f);
    }
    
    void startCamera()
    {
        cv::VideoCapture cap(0);
        if (!cap.isOpened()) {
            std::cerr << "无法打开相机" << std::endl;
            return;
        }
        
        cv::Mat frame;
        while (true) {
            cap >> frame;
            if (frame.empty()) break;
            
            // 执行分类
            ClassificationResult result;
            if (dlProcessor_->classifyImage(frame, result)) {
                // 在图像上显示结果
                std::string text = result.className + " (" + 
                    std::to_string(result.confidence) + ")";
                cv::putText(frame, text, cv::Point(10, 30), 
                    cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 255, 0), 2);
            }
            
            cv::imshow("实时分类", frame);
            if (cv::waitKey(1) == 27) break; // ESC键退出
        }
    }

private:
    DLProcessor* dlProcessor_;
};
```

## 性能优化

### 1. 模型优化
- **量化**: 使用INT8量化减少模型大小和推理时间
- **剪枝**: 移除不重要的连接以减少计算量
- **蒸馏**: 使用知识蒸馏训练更小的模型

### 2. 预处理优化
```cpp
// 预分配内存
cv::Mat blob;
blob.create(1, 3, CV_32F);

// 使用固定尺寸避免重复分配
processor->setInputSize(cv::Size(224, 224));

// 批量处理提高效率
std::vector<cv::Mat> batch;
// ... 添加图像到batch
processor->classifyBatch(batch, results);
```

### 3. GPU加速
```cpp
// 在初始化时启用GPU后端
cv::dnn::Net net = cv::dnn::readNet(modelPath);
net.setPreferableBackend(cv::dnn::DNN_BACKEND_CUDA);
net.setPreferableTarget(cv::dnn::DNN_TARGET_CUDA);
```

### 4. 多线程处理
```cpp
// 使用Qt的并发框架
#include <QtConcurrent>

QFuture<ClassificationResult> future = QtConcurrent::run([=]() {
    ClassificationResult result;
    dlProcessor->classifyImage(image, result);
    return result;
});
```

## 故障排除

### 常见错误及解决方案

#### 1. 模型加载失败
**错误**: "无法加载模型文件"
**原因**: 
- 文件路径错误
- 模型格式不支持
- 缺少配置文件

**解决方案**:
```cpp
// 检查文件是否存在
if (!QFile::exists(modelPath)) {
    qDebug() << "模型文件不存在:" << modelPath;
    return false;
}

// 对于Caffe模型，确保有prototxt文件
if (modelPath.endsWith(".caffemodel")) {
    QString prototxt = modelPath;
    prototxt.replace(".caffemodel", ".prototxt");
    if (!QFile::exists(prototxt)) {
        qDebug() << "缺少prototxt文件:" << prototxt;
        return false;
    }
}
```

#### 2. 分类结果异常
**错误**: 置信度始终很低或结果不准确
**原因**:
- 预处理参数不正确
- 输入尺寸不匹配
- 模型训练数据与实际数据差异大

**解决方案**:
```cpp
// 检查并调整预处理参数
processor->setPreprocessParams(
    cv::Scalar(0.485, 0.456, 0.406),  // ImageNet均值
    cv::Scalar(0.229, 0.224, 0.225),  // ImageNet标准差
    1.0/255.0,                        // 归一化到[0,1]
    true                              // BGR转RGB
);

// 确保输入尺寸正确
processor->setInputSize(cv::Size(224, 224));
```

#### 3. 内存泄漏
**错误**: 长时间运行后内存占用持续增长
**原因**: 
- 未正确释放OpenCV Mat对象
- 批量处理时累积内存

**解决方案**:
```cpp
// 及时释放Mat对象
{
    cv::Mat image = cv::imread("image.jpg");
    ClassificationResult result;
    processor->classifyImage(image, result);
    // image会在作用域结束时自动释放
}

// 批量处理时分批进行
const int BATCH_SIZE = 32;
for (int i = 0; i < totalImages; i += BATCH_SIZE) {
    std::vector<cv::Mat> batch;
    // 添加一批图像
    // 处理这一批
    // batch会自动释放
}
```

#### 4. 性能问题
**错误**: 分类速度过慢
**原因**:
- 未启用GPU加速
- 输入尺寸过大
- 频繁的内存分配

**解决方案**:
```cpp
// 启用GPU加速（如果可用）
#ifdef OPENCV_DNN_CUDA
net.setPreferableBackend(cv::dnn::DNN_BACKEND_CUDA);
net.setPreferableTarget(cv::dnn::DNN_TARGET_CUDA);
#endif

// 使用合适的输入尺寸
processor->setInputSize(cv::Size(224, 224)); // 而不是更大的尺寸

// 预分配内存
cv::Mat blob;
cv::dnn::blobFromImage(image, blob, 1.0/255.0, cv::Size(224, 224));
```

## 常见问题

### Q1: 支持哪些深度学习框架的模型？
**A**: 目前支持以下格式：
- ONNX (.onnx) - 推荐格式
- TensorFlow (.pb)
- Caffe (.caffemodel + .prototxt)
- Darknet (.weights + .cfg)

### Q2: 如何提高分类准确率？
**A**: 
1. 确保预处理参数与训练时一致
2. 使用合适的输入尺寸
3. 调整置信度阈值
4. 检查训练数据质量

### Q3: 可以同时加载多个模型吗？
**A**: 可以创建多个DLProcessor实例：
```cpp
DLProcessor* processor1 = new DLProcessor();
DLProcessor* processor2 = new DLProcessor();
processor1->initModel("model1.onnx");
processor2->initModel("model2.onnx");
```

### Q4: 如何处理不同尺寸的输入图像？
**A**: DLProcessor会自动调整图像尺寸：
```cpp
// 设置目标尺寸
processor->setInputSize(cv::Size(224, 224));

// 任何尺寸的图像都会被调整到224x224
cv::Mat image1 = cv::imread("1920x1080.jpg");
cv::Mat image2 = cv::imread("640x480.jpg");
// 两者都会被处理为224x224
```

### Q5: 如何集成到现有的Qt应用中？
**A**: 
1. 包含头文件：`#include "DLProcessor.h"`
2. 创建实例：`DLProcessor* processor = new DLProcessor(this);`
3. 连接信号槽处理结果
4. 在需要的地方调用分类方法

### Q6: 支持GPU加速吗？
**A**: 支持，需要：
1. OpenCV编译时启用CUDA支持
2. 安装NVIDIA GPU驱动和CUDA
3. 在代码中启用GPU后端

### Q7: 如何调试分类结果？
**A**: 
1. 检查置信度值
2. 验证预处理参数
3. 可视化输入图像
4. 使用已知的测试图像验证

## 技术支持

如果遇到问题，请：
1. 检查本文档的故障排除部分
2. 查看项目的GitHub Issues页面
3. 联系开发团队获取技术支持

## 版本历史

### v1.0.0 (2024-01-01)
- 初始版本发布
- 支持ONNX、TensorFlow、Caffe、Darknet模型格式
- 实现二分类功能
- 提供Qt GUI演示应用
- 完整的API文档和使用指南

## 许可证

本项目采用 MIT 许可证，详情请参见 LICENSE 文件。

## 贡献指南

欢迎贡献代码和改进建议：
1. Fork 项目仓库
2. 创建功能分支
3. 提交更改
4. 发起 Pull Request

---

**注意**: 本文档会持续更新，请关注最新版本以获取最准确的信息。
